tree$edge.length = tree$edge.length/max(branching.times(tree))
tip_states = simulate_bm_model(tree, diffusivity=1)$tip_states
return(tip_states)
}
out <- list()
for(i in 1:12){
print(i)
out[[i]] <- sapply(1:1000, function(x) var(quick_func(2^i)))
}
plot_data <- do.call(cbind, out)
colnames(plot_data) <- 2^(1:12)
boxplot(plot_data, ylab = "tip variance", xlab = "n taxa", main = "variance at tips under BM with 1000 sims")
abline(h = 2, col = "red", lwd = 2)
library(castor)
library(ape)
quick_func <- function(ntaxa){
tree = generate_random_tree(list(birth_rate_intercept=1),max_tips=ntaxa)$tree
tree$edge.length = tree$edge.length/max(branching.times(tree))
tip_states = simulate_bm_model(tree, diffusivity=1)$tip_states
return(c(bl=sum(tree$edge.length), x_var = var(tip_states)))
}
out <- list()
sapply(1:1000, function(x) var(quick_func(2^i)))
i = 2
sapply(1:1000, function(x) var(quick_func(2^i)))
sapply(1:1000, function(x) var(quick_func_2(2^i)))
quick_func_2 <- function(ntaxa){
tree = generate_random_tree(list(birth_rate_intercept=1),max_tips=ntaxa)$tree
tree$edge.length = tree$edge.length/max(branching.times(tree))
tip_states = simulate_bm_model(tree, diffusivity=1)$tip_states
return(c(bl=sum(tree$edge.length), x_var = var(tip_states)))
}
out <- list()
out[[i]] <- sapply(1:1000, function(x) var(quick_func_2(2^i)))
out[[i]]
quick_func_2
out[[i]] <- sapply(1:1000, function(x) (quick_func_2(2^i)))
out[[i]]
out[[i]] <- t(sapply(1:1000, function(x) (quick_func_2(2^i))))
out[[i]]
cbind(ntaxa = 2^i, out)
2^i
cbind(ntaxa = 2^i, out)
for(i in 1:13){
print(i)
out[[i]] <- t(sapply(1:1000, function(x) (quick_func_2(2^i))))
}
plot(plot_data)
?corHMM
library(corHMM)
?corHMM
data(primates)
phy <- multi2di(primates[[1]])
data <- primates[[2]]
MK_3state <- corHMM(phy = phy, data = data, rate.cat = 1)
MK_3state
dredge_test <- corHMM:::corHMMDredge(phy = phy, data = data, max.rate.cat = 1)
corHMMDredge <- function(phy, data, max.rate.cat, node.states = "marginal", fixed.nodes=FALSE, root.p="yang", ip=NULL, nstarts=0, n.cores=1, get.tip.states = FALSE, lewis.asc.bias = FALSE, collapse = TRUE, lower.bound = 1e-9, upper.bound = 100, opts=NULL){
# Checks to make sure node.states is not NULL.  If it is, just returns a diagnostic message asking for value.
if(is.null(node.states)){
obj <- NULL
obj$loglik <- NULL
obj$diagnostic <- paste("No model for ancestral states selected.  Please pass one of the following to corHMM command for parameter \'node.states\': joint, marginal, scaled, or none.")
return(obj)
} else { # even if node.states is not NULL, need to make sure its one of the three valid options
valid.models <- c("joint", "marginal", "scaled", "none")
if(!any(valid.models == node.states)){
obj <- NULL
obj$loglik <- NULL
obj$diagnostic <- paste("\'",node.states, "\' is not valid for ancestral state reconstruction method.  Please pass one of the following to corHMM command for parameter \'node.states\': joint, marginal, scaled, or none.",sep="")
return(obj)
}
if(length(node.states) > 1){ # User did not enter a value, so just pick marginal.
node.states <- "marginal"
cat("No model selected for \'node.states\'. Will perform marginal ancestral state estimation.\n")
}
}
if(fixed.nodes == FALSE){
if(!is.null(phy$node.label)){
phy$node.label <- NULL
cat("You specified \'fixed.nodes=FALSE\' but included a phy object with node labels. These node labels have been removed.\n")
}
}
#Ensures that weird root state probabilities that do not sum to 1 are input:
if(!is.null(root.p)){
if(!is.character(root.p)){
root.p <- root.p/sum(root.p)
}
}
input.data <- data
nCol <- dim(data)[2]
CorData <- corProcessData(data, collapse = collapse)
data.legend <- data <- CorData$corData
# nObs <- length(CorData$ObservedTraits)
if(length(grep("&", CorData$corData[,2])) > 0){
non_and_chars <- as.numeric(CorData$corData[,2][-grep("&", CorData$corData[,2])])
and_chars <- as.numeric(unlist(strsplit(CorData$corData[,2][grep("&", CorData$corData[,2])], "&")))
nObs <- max(c(non_and_chars, and_chars))
}else{
nObs <- max(as.numeric(CorData$corData[,2]))
}
# Checks to make sure phy & data have same taxa. Fixes conflicts (see match.tree.data function).
matching <- match.tree.data(phy,data)
data <- matching$data
phy <- matching$phy
# Will not perform reconstructions on invariant characters (unless rate params have been given!)
if(nlevels(as.factor(data[,1])) <= 1 & !is.null(p)){
obj <- NULL
obj$loglik <- NULL
obj$diagnostic <- paste("Character is invariant. Analysis stopped.",sep="")
return(obj)
} else {
# Still need to make sure second level isnt just an ambiguity
lvls <- as.factor(data[,1])
if(nlevels(as.factor(data[,1])) == 2 && length(which(lvls == "?"))){
obj <- NULL
obj$loglik <- NULL
obj$diagnostic <- paste("Character is invariant. Analysis stopped.",sep="")
return(obj)
}
}
if(any(phy$edge.length<=1e-5)){
warning("Branch lengths of 0 detected. Adding 1e-5 to these branches.", immediate. = TRUE)
#   phy$edge.length[phy$edge.length<=1e-5] <- 1e-5
phy$edge.length <- phy$edge.length + 1e-5 # changed to add 1e-5 based on suggestion from Hedvig SkirgÃ¥rd (github issue #27)
}
#Creates the data structure and orders the rows to match the tree.
data.sort <- data.frame(data[,2], data[,2],row.names=data[,1])
data.sort <- data.sort[phy$tip.label,]
counts <- table(data.sort[,1])
levels <- levels(as.factor(data.sort[,1]))
cols <- as.factor(data.sort[,1])
cat("State distribution in data:\n")
cat("States:",levels,"\n",sep="\t")
cat("Counts:",counts,"\n",sep="\t")
#Some initial values for use later
k=2
if(upper.bound < lower.bound){
cat("Your upper bound is smaller than your lower bound.\n")
}
lb <- log(lower.bound)
ub <- log(upper.bound)
order.test <- TRUE
obj <- NULL
nb.tip <- length(phy$tip.label)
nb.node <- phy$Nnode
rate.cat <- max.rate.cat
root.p <- root.p
nstarts <- nstarts
ip <- ip
p <- NULL
model.set.final <- rate.cat.set.corHMM.JDB(phy=phy,data=input.data,rate.cat=rate.cat,ntraits=nObs,model="ARD",rate.mat=NULL, collapse=collapse)
phy <- reorder(phy, "pruningwise")
lower = rep(lb, model.set.final$np)
upper = rep(ub, model.set.final$np)
if(is.null(opts)){
opts <- list("algorithm"="NLOPT_LN_SBPLX", "maxeval"="1000000", "ftol_rel"=.Machine$double.eps^0.5)
}
if(is.null(ip)){
#If a user-specified starting value(s) is not supplied this begins loop through a set of randomly chosen starting values:
#Sets parameter settings for random restarts by taking the parsimony score and dividing
#by the total length of the tree
cat("Beginning thorough optimization search -- performing", nstarts, "random restarts", "\n")
taxa.missing.data.drop <- which(is.na(data.sort[,1]))
if(length(taxa.missing.data.drop) != 0){
tip.labs <- names(taxa.missing.data.drop)
dat <- as.matrix(data.sort)
dat.red <- dat[-taxa.missing.data.drop,]
phy.red <- drop.tip(phy, taxa.missing.data.drop)
dat.red <- phyDat(dat.red,type="USER", levels=levels)
phy.tmp <- multi2di(phy.red)
par.score <- parsimony(phy.tmp, dat.red, method="fitch")/2
}else{
dat <- as.matrix(data.sort)
dat <- phyDat(dat,type="USER", levels=levels)
phy.tmp <- multi2di(phy)
par.score <- parsimony(phy.tmp, dat, method="fitch")/2
}
tl <- sum(phy$edge.length)
mean.change = par.score/tl
random.restart<-function(nstarts){
tmp = matrix(,1,ncol=(1+model.set.final$np))
if(mean.change==0){
starts=rep(0.01+exp(lb), model.set.final$np)
}else{
starts<-sort(rexp(model.set.final$np, 1/mean.change), decreasing = TRUE)
}
starts[starts < exp(lb)] = exp(lb)
starts[starts > exp(ub)] = exp(lb)
out = nloptr(x0=log(starts), eval_f=dev.corhmm.dredge, lb=lower, ub=upper, opts=opts, phy=phy, liks=model.set.final$liks,Q=model.set.final$Q,rate=model.set.final$rate,root.p=root.p, rate.cat = rate.cat, order.test = order.test, lewis.asc.bias = lewis.asc.bias)
tmp[,1] = out$objective
tmp[,2:(model.set.final$np+1)] = out$solution
tmp
}
if(n.cores > 1){
restart.set<-mclapply(1:nstarts, random.restart, mc.cores=n.cores)
}else{
restart.set<-lapply(1:nstarts, random.restart)
}
#Finds the best fit within the restart.set list
best.fit<-which.min(unlist(lapply(restart.set, function(x) x[1])))
#Generates an object to store results from restart algorithm:
out<-NULL
out$objective=unlist(restart.set[[best.fit]][,1])
out$solution=unlist(restart.set[[best.fit]][,2:(model.set.final$np+1)])
loglik <- -out$objective
est.pars <- exp(out$solution)
}else{
# the user has specified initial params
cat("Beginning subplex optimization routine -- Starting value(s):", ip, "\n")
ip=ip
out = nloptr(x0=rep(log(ip), length.out = model.set.final$np), eval_f=dev.corhmm, lb=lower, ub=upper, opts=opts, phy=phy,liks=model.set.final$liks,Q=model.set.final$Q,rate=model.set.final$rate,root.p=root.p, rate.cat = rate.cat, order.test = order.test, lewis.asc.bias = lewis.asc.bias)
loglik <- -out$objective
est.pars <- exp(out$solution)
}
}
library(corHMM)
data(primates)
phy <- multi2di(primates[[1]])
data <- primates[[2]]
MK_3state <- corHMM(phy = phy, data = data, rate.cat = 1)
MK_3state
dredge_test <- corHMM:::corHMMDredge(phy = phy, data = data, max.rate.cat = 1)
debug(corHMM:::corHMMDredge)
dredge_test <- corHMM:::corHMMDredge(phy = phy, data = data, max.rate.cat = 1)
library(corHMM)
data(primates)
phy <- multi2di(primates[[1]])
data <- primates[[2]]
MK_3state <- corHMM(phy = phy, data = data, rate.cat = 1)
MK_3state
dredge_test <- corHMM:::corHMMDredge(phy = phy, data = data, max.rate.cat = 1)
library(corHMM)
library(TreeSim)
n = 100
numbsim = 1
lambda = 1
mu = 0.5
Q <- matrix(c(-1,1,1,-1), 2, 2, byrow = TRUE)
root.p <- c(1,0)
phy <- sim.bd.taxa(n, numbsim, lambda, mu, frac = 1, complete = FALSE, stochsampling = FALSE)[[1]]
dat <- corHMM:::simMarkov(phy, Q, root.p)
cor_dat <- data.frame(sp = names(dat$TipStates), d = dat$TipStates)
plot(phy, show.tip.label = FALSE)
tiplabels(pch = 16, col = dat$TipStates, cex = 0.5)
res_unreg <- corHMM(phy, cor_dat, 1)
res_reg <- corHMM:::corHMMDredge(phy, cor_dat, 1, node.states = "none")
res_unreg
res_reg
res_unreg
res_reg
nsim = 100
n = 100
numbsim = 1
lambda = 1
mu = 0.5
Q <- matrix(c(-1,1,1,-1), 2, 2, byrow = TRUE)
root.p <- c(1,0)
phy <- sim.bd.taxa(n, numbsim, lambda, mu, frac = 1, complete = FALSE, stochsampling = FALSE)[[1]]
dat <- lapply(1:nsim, corHMM:::simMarkov(phy, Q, root.p))
phy <- sim.bd.taxa(n, numbsim, lambda, mu, frac = 1, complete = FALSE, stochsampling = FALSE)[[1]]
dat <- lapply(1:nsim, corHMM:::simMarkov(phy, Q, root.p))
dat <- lapply(1:nsim, function(x) corHMM:::simMarkov(phy, Q, root.p))
dat
cor_dat <- lapply(dat, function(x) data.frame(sp = names(x$TipStates), d = x$TipStates))
cor_dat
res_reg <- corHMM:::corHMMDredge(phy, cor_dat[[1]], 1)
res_reg
library(corHMM)
library(TreeSim)
nsim = 100
n = 100
numbsim = 1
lambda = 1
mu = 0.5
Q <- matrix(c(-1,1,1,-1), 2, 2, byrow = TRUE)
root.p <- c(1,0)
phy <- sim.bd.taxa(n, numbsim, lambda, mu, frac = 1, complete = FALSE, stochsampling = FALSE)[[1]]
dat <- lapply(1:nsim, function(x) corHMM:::simMarkov(phy, Q, root.p))
cor_dat <- lapply(dat, function(x) data.frame(sp = names(x$TipStates), d = x$TipStates))
res_reg <- corHMM:::corHMMDredge(phy, cor_dat[[1]], 1)
res_reg
res_unreg <- lapply(cor_dat, function(x) corHMM(phy, x, 1))
library(parallel)
res_unreg <- mclapply(cor_dat, function(x) corHMM(phy, x, 1), mc.cores = 10)
res_unreg <- mclapply(cor_dat, function(x) corHMM(phy, x, 1), mc.cores = 4)
res_unreg <- mclapply(cor_dat, function(x) corHMM(phy, x, 1), mc.cores = 10)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1), mc.cores = 10)
res_unreg
res_reg
res_unreg[[1]]$solution
unlist(res_unreg[[1]]$solution)
c(res_unreg[[1]]$solution)
c(res_unreg[[1]]$solution)[c(3,2)]
do.call(rbind, lapply(res_unreg, function(x) c(x[[1]]$solution)[c(3,2)]))
lapply(res_unreg, function(x) c(x[[1]]$solution)[c(3,2)])
do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
boxplot(rbind(df_unreg, df_reg)); abline(h = 1)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "waiting"), mc.cores = 10)
boxplot(cbind(df_unreg, df_reg)); abline(h = 1)
plot_data <- cbind(df_unreg, df_reg)
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
boxplot(plot_data); abline(h = 1)
res_reg
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
plot_data <- cbind(df_unreg, df_reg)
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
boxplot(plot_data); abline(h = 1)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "distance"), mc.cores = 10)
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
plot_data <- cbind(df_unreg, df_reg)
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
boxplot(plot_data); abline(h = 1)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "logl1"), mc.cores = 10)
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
plot_data <- cbind(df_unreg, df_reg)
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
boxplot(plot_data); abline(h = 1)
df_unreg - 1
bias_unreg = colMeans(df_unreg - 1)
bias = colMeans(plot_data - 1)
bias
bias = colMeans(plot_data) 1
bias = colMeans(plot_data) - 1
bias
colMeans(plot_data)
apply(plot_data, 2, var)
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 1)^2)
mse
rmse = sqrt(colMeans((plot_data - 1)^2))
rmse
data.frame(bias, varr, mse, rmse)
t(data.frame(bias, varr, mse, rmse))
log(1)
plot_data <- log(cbind(df_unreg, df_reg))
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
bias = colMeans(plot_data) - 0
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 0)^2)
rmse = sqrt(colMeans((plot_data - 1)^2))
t(data.frame(bias, varr, mse, rmse))
rmse = sqrt(colMeans((plot_data - 0)^2))
t(data.frame(bias, varr, mse, rmse))
var(1,1,1,10)
var(c(1,1,1,10))
var(c(1,1,1,1))
library(corHMM)
library(TreeSim)
library(parallel)
nsim = 100
n = 100
numbsim = 1
lambda = 1
mu = 0.5
Q <- matrix(c(-1,1,1,-1), 2, 2, byrow = TRUE)
root.p <- c(1,0)
phy <- sim.bd.taxa(n, numbsim, lambda, mu, frac = 1, complete = FALSE, stochsampling = FALSE)[[1]]
dat <- lapply(1:nsim, function(x) corHMM:::simMarkov(phy, Q, root.p))
cor_dat <- lapply(dat, function(x) data.frame(sp = names(x$TipStates), d = x$TipStates))
res_unreg <- mclapply(cor_dat, function(x) corHMM(phy, x, 1), mc.cores = 10)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "varr"), mc.cores = 10)
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
plot_data <- log(cbind(df_unreg, df_reg))
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
bias = colMeans(plot_data) - 0
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 0)^2)
rmse = sqrt(colMeans((plot_data - 0)^2))
t(data.frame(bias, varr, mse, rmse))
boxplot(plot_data); abline(h = 1)
boxplot(plot_data); abline(h = 0)
bias = colMeans(plot_data) - 1
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 1)^2)
rmse = sqrt(colMeans((plot_data - 1)^2))
t(data.frame(bias, varr, mse, rmse))
boxplot(plot_data); abline(h = 1)
plot_data <- (cbind(df_unreg, df_reg))
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
bias = colMeans(plot_data) - 1
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 1)^2)
rmse = sqrt(colMeans((plot_data - 1)^2))
t(data.frame(bias, varr, mse, rmse))
boxplot(plot_data); abline(h = 1)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "logl1"), mc.cores = 10)
df_unreg <- do.call(rbind, lapply(res_unreg, function(x) c(x$solution)[c(3,2)]))
df_reg <- do.call(rbind, lapply(res_reg, function(x) c(x$solution)[c(3,2)]))
plot_data <- (cbind(df_unreg, df_reg))
colnames(plot_data) <- c("01_unreg", "10_unreg", "01_reg", "10_reg")
bias = colMeans(plot_data) - 1
varr = apply(plot_data, 2, var)
mse = colMeans((plot_data - 1)^2)
rmse = sqrt(colMeans((plot_data - 1)^2))
t(data.frame(bias, varr, mse, rmse))
boxplot(plot_data); abline(h = 1)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "varrlog"), mc.cores = 10)
res_reg <- mclapply(cor_dat, function(x) corHMM:::corHMMDredge(phy, x, 1, pen_type = "varrlog"), mc.cores = 10)
library(dentist)
dentist:::plot.dentist()
?dentist:::plot.dentist()
setwd("~/corhmm-dredge/")
library(corHMM)
library(parallel)
library(MASS)
library(dplyr)
library(ggplot2)
library(tidyr)
library(gghalves)
source("code/utils.R")
trees <- lapply(dir("trees/", full.names = TRUE), read.tree)
phy <- trees[[1]]
nSim = 100
############### Simulation scenario 1 ####################
# which simulation number
simulation <- "01"
# the various file names
par_table_name <- paste0("par_table-", simulation, ".csv")
full_dat_name <- paste0("full_data-", simulation, ".RDS")
cor_dat_name <- paste0("cor_data-", simulation, ".RDS")
sim_res_files <- dir("res/", full.names = TRUE)[grep(paste0("res", simulation, "_"), dir("res/"))]
# load everything
index_mat <- get_index_mat(nChar=1, nStates=2, nRateClass=1)
tmp <- get_par_table(index_mat, nSim, mean = 0, sd = 0.25)
par_table <- read.csv(paste0("parameter_tables/", par_table_name))
colnames(par_table) <- colnames(tmp)
rate_mats <- get_rate_mats(index_mat, par_table)
full_dat <- readRDS(paste0("data/", full_dat_name))
cor_dat <- lapply(full_dat, "[[", "cor_dat")
# load results
res_list <- lapply(sim_res_files, readRDS)
names(res_list) <- gsub(".*_", "", sim_res_files) %>% gsub(".RDS", "", .)
# format data and compare results
df_list <- lapply(res_list, function(x) do.call(rbind, lapply(x, get_solution_from_res)))
df_true <- do.call(rbind, lapply(full_dat, function(x) get_par_from_rate_mat(x, index_mat)))
ntips <- do.call(rbind, lapply(full_dat, function(x) length(x$phy$tip.label)))
df_true_long <- get_better_df(df_true, colnames(tmp), "true", ntips)
df_long_list <- list()
for(i in 1:length(df_list)){
df_long_list[[i]] <- get_better_df(df_list[[i]], colnames(tmp), names(res_list)[i], ntips)
df_long_list[[i]]$diff <- df_long_list[[i]]$value - df_true_long$value
}
df_all <- do.call(rbind, df_long_list)
# Calculate MSE and RMSE for df_reg_diff
df_summary <- df_all %>%
group_by(ntips, type, par) %>%
summarize(
bias = mean(diff),
var = var(diff),
mse= mean(diff^2),  # Calculate MSE
rmse = sqrt(mse)     # Calculate RMSE
)
print(df_summary)
setwd("~/corhmm-dredge/")
library(corHMM)
library(parallel)
library(MASS)
library(dplyr)
library(ggplot2)
library(tidyr)
library(gghalves)
source("code/utils.R")
trees <- lapply(dir("trees/", full.names = TRUE), read.tree)
phy <- trees[[1]]
nSim = 100
############### Simulation scenario 1 ####################
# which simulation number
simulation <- "01"
# the various file names
par_table_name <- paste0("par_table-", simulation, ".csv")
full_dat_name <- paste0("full_data-", simulation, ".RDS")
cor_dat_name <- paste0("cor_data-", simulation, ".RDS")
sim_res_files <- dir("res/", full.names = TRUE)[grep(paste0("res", simulation, "_"), dir("res/"))]
# load everything
index_mat <- get_index_mat(nChar=1, nStates=2, nRateClass=1)
tmp <- get_par_table(index_mat, nSim, mean = 0, sd = 0.25)
par_table <- read.csv(paste0("parameter_tables/", par_table_name))
colnames(par_table) <- colnames(tmp)
rate_mats <- get_rate_mats(index_mat, par_table)
full_dat <- readRDS(paste0("data/", full_dat_name))
cor_dat <- lapply(full_dat, "[[", "cor_dat")
# load results
res_list <- lapply(sim_res_files, readRDS)
names(res_list) <- gsub(".*_", "", sim_res_files) %>% gsub(".RDS", "", .)
# format data and compare results
df_list <- lapply(res_list, function(x) do.call(rbind, lapply(x, get_solution_from_res)))
df_true <- do.call(rbind, lapply(full_dat, function(x) get_par_from_rate_mat(x, index_mat)))
ntips <- do.call(rbind, lapply(full_dat, function(x) length(x$phy$tip.label)))
df_true_long <- get_better_df(df_true, colnames(tmp), "true", ntips)
df_long_list <- list()
for(i in 1:length(df_list)){
df_long_list[[i]] <- get_better_df(df_list[[i]], colnames(tmp), names(res_list)[i], ntips)
df_long_list[[i]]$diff <- df_long_list[[i]]$value - df_true_long$value
}
df_all <- do.call(rbind, df_long_list)
# Calculate MSE and RMSE for df_reg_diff
df_summary <- df_all %>%
group_by(ntips, type, par) %>%
summarize(
bias = mean(diff),
var = var(diff),
mse= mean(diff^2),  # Calculate MSE
rmse = sqrt(mse)     # Calculate RMSE
)
print(df_summary)
